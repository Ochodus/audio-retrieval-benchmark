# Audio Retrieval with Natural Language Queries

This repository is the implementation of [Audio Retrieval with Natural Language Queries](https://arxiv.org/pdf/2105.02192.pdf) and it is based on the [Use What You Have: Video retrieval using representations from collaborative experts](https://github.com/albanie/collaborative-experts) repo. Datasets used in this paper are [AudioCaps](https://www.aclweb.org/anthology/N19-1011.pdf), [CLOTHO](https://arxiv.org/pdf/1910.09387.pdf), [Activity-Net](https://arxiv.org/pdf/1705.00754.pdf) and [QuerYD](https://arxiv.org/pdf/2011.11071.pdf).

More information can be found at our project page: https://www.robots.ox.ac.uk/~vgg/research/audio-retrieval/

----
:exclamation: An extension of this work along with the new SoundDescs dataset for audio retrieval can be found [here](https://github.com/akoepke/audio-retrieval-benchmark). :exclamation:
----

### Requirements

We used PyTorch 1.7.1., CUDA 10.1, and Python 3.7 to generate results and models. The required libraries for running this code can be found in `requirements/requirements.txt`.

```
conda create --name audio-retrieval python=3.7
conda activate audio-retrieval
pip install -r requirements/requirements.txt
```

To be able to run the code below, features extracted from various datasets need to be downloaded. If there is not enough space in your working location to store some of these features (for AudioCaps the file is 6GB while the others are under 1GB) then you will need to create a folder called `data` inside this repository which should be a symlink to a folder with enough space. As an example, run the following from the audio-experts code-base.

```
ln -s <path-where-data-can-be-saved> data
```

To download features for each dataset, follow the steps [here](misc/exps-names.md)

### Evaluating a pretrained model on multiple seeds and reproducing results
To reproduce the results in tables below, multiple models trained with different seeds need to be downloaded and evaluated on the test sets.

The steps needed to reproduce the results are:
1. Select the experiment to be reproduced which is in the form `<dataset-name>-<config-file-name>`. Tables with experiments names and the corresponding form can be found in [`misc/exps-names.md`](misc/exps-names.md).
2. Download the features and splits corresponding to the dataset for which the experiment is run. For example, for AudioCaps run:
```
# fetch the pretrained experts for AudioCaps 
python3 misc/sync_experts.py --dataset AudioCaps
```
Additional examples for the datasets used in this paper can be found in [`misc/exps-names.md`](misc/exps-names.md).

3. Running the `eval.py` script.

For example, to reproduce the experiments for AudioCaps with all visual and audio experts, run the following line:
```
python eval.py --experiment audiocaps-train-full-ce-r2p1d-inst-vggish-vggsound
```
If the --experiment flag is not provided, the `eval.py` script will download and evaluate all models on the test set.


### Training a new model

Training a new audio-text embedding requires:
1. The pretrained experts for the dataset used for training, which should be located in `<root>/data/<dataset-name>/symlinked-feats` (this will be done automatically by the [utility script](misc/sync_experts.py), or can be done manually). Examples can be found in [`misc/exps-names.md`](misc/exps-names.md).
2. A `config.json` file.  You can define your own, or use one of the provided configs in the [configs](configs) directory.

Training is then performed with the following command:
```
python3 train.py --config <path-to-config.json> --device <gpu-id>
```
where `<gpu-id>` is the index of the GPU to train on.  This option can be ommitted for training on the CPU.

For example, to train a new embedding for the CLOTHO dataset, run the following sequence of commands:

```
# fetch the pretrained experts for CLOTHO 
python3 misc/sync_experts.py --dataset CLOTHO

# Train the model
python3 train.py --config configs/clotho/train-vggish-vggsound.json --device 0
```


### AudioCaps

#### These are the retrieval results obtained for the AudioCaps dataset when using only audio experts:


| Experts | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Geom | params | Links |
| ----- | ---- | --- | --- | ---- | ---- | --- | --- | ----- | -- | -- |
| CE - VGGish   | t2v  | <sub><sup>18.0<sub>(0.2)</sub></sup></sub> | <sub><sup>46.8<sub>(0.2)</sub></sup></sub> | <sub><sup>62.0<sub>(0.5)</sub></sup></sub> | <sub><sup>88.5<sub>(0.2)</sub></sup></sub> | <sub><sup>6.0<sub>(0.0)</sub></sup></sub> | <sub><sup>23.6<sub>(1.3)</sub></sup></sub> | <sub><sup>37.4<sub>(0.2)</sub></sup></sub> | 7.39M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-only-audio/c0b5bc86/seed-0/2021-06-10_15-34-48/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-only-audio/c0b5bc86/seed-0/2021-06-10_15-34-48/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-only-audio/c0b5bc86/seed-0/2021-06-10_15-34-48/summary-seed-0_seed-1_seed-2.json) |
| CE - VGGish    | v2t  | <sub><sup>21.0<sub>(0.8)</sub></sup></sub> | <sub><sup>48.3<sub>(1.8)</sub></sup></sub> | <sub><sup>62.7<sub>(1.6)</sub></sup></sub> | <sub><sup>87.3<sub>(0.4)</sub></sup></sub> | <sub><sup>6.0<sub>(0.0)</sub></sup></sub> | <sub><sup>27.4<sub>(1.2)</sub></sup></sub> | <sub><sup>39.9<sub>(0.6)</sub></sup></sub> | 7.39M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-only-audio/c0b5bc86/seed-0/2021-06-10_15-34-48/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-only-audio/c0b5bc86/seed-0/2021-06-10_15-34-48/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-only-audio/c0b5bc86/seed-0/2021-06-10_15-34-48/summary-seed-0_seed-1_seed-2.json) |
| CE - VGGSound    | t2v  | <sub><sup>20.5<sub>(0.6)</sub></sup></sub> | <sub><sup>52.1<sub>(0.4)</sub></sup></sub> | <sub><sup>67.0<sub>(1.0)</sub></sup></sub> | <sub><sup>91.1<sub>(1.6)</sub></sup></sub> | <sub><sup>5.0<sub>(0.0)</sub></sup></sub> | <sub><sup>20.6<sub>(2.8)</sub></sup></sub> | <sub><sup>41.5<sub>(0.7)</sub></sup></sub> | 12.12M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-only-vggsound/afab0e0c/seed-0/2021-06-16_01-21-37/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-only-vggsound/afab0e0c/seed-0/2021-06-16_01-21-37/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-only-vggsound/afab0e0c/seed-0/2021-06-16_01-21-37/summary-seed-0_seed-1_seed-2.json) |
| CE - VGGSound   | v2t  | <sub><sup>24.6<sub>(0.9)</sub></sup></sub> | <sub><sup>55.9<sub>(0.3)</sub></sup></sub> | <sub><sup>70.4<sub>(0.4)</sub></sup></sub> | <sub><sup>92.4<sub>(0.6)</sub></sup></sub> | <sub><sup>4.3<sub>(0.6)</sub></sup></sub> | <sub><sup>19.9<sub>(1.4)</sub></sup></sub> | <sub><sup>45.9<sub>(0.6)</sub></sup></sub> | 12.12M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-only-vggsound/afab0e0c/seed-0/2021-06-16_01-21-37/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-only-vggsound/afab0e0c/seed-0/2021-06-16_01-21-37/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-only-vggsound/afab0e0c/seed-0/2021-06-16_01-21-37/summary-seed-0_seed-1_seed-2.json) |
| CE - VGGish + VGGSound    | t2v  | <sub><sup>23.1<sub>(0.8)</sub></sup></sub> | <sub><sup>55.1<sub>(0.9)</sub></sup></sub> | <sub><sup>70.7<sub>(0.7)</sub></sup></sub> | <sub><sup>92.9<sub>(0.5)</sub></sup></sub> | <sub><sup>4.7<sub>(0.6)</sub></sup></sub> | <sub><sup>16.5<sub>(0.6)</sub></sup></sub> | <sub><sup>44.8<sub>(0.8)</sub></sup></sub> | 21.86M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-vggish-vggsound/7e2eda12/seed-0/2021-06-09_17-06-26/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-vggish-vggsound/7e2eda12/seed-0/2021-06-09_17-06-26/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-vggish-vggsound/7e2eda12/seed-0/2021-06-09_17-06-26/summary-seed-0_seed-1_seed-2.json) |
| CE - VGGish + VGGSound   | v2t  | <sub><sup>25.1<sub>(0.9)</sub></sup></sub> | <sub><sup>57.1<sub>(1.0)</sub></sup></sub> | <sub><sup>73.2<sub>(1.6)</sub></sup></sub> | <sub><sup>92.5<sub>(0.2)</sub></sup></sub> | <sub><sup>4.0<sub>(0.0)</sub></sup></sub> | <sub><sup>17.0<sub>(0.1)</sub></sup></sub> | <sub><sup>47.2<sub>(1.1)</sub></sup></sub> | 21.86M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-vggish-vggsound/7e2eda12/seed-0/2021-06-09_17-06-26/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-vggish-vggsound/7e2eda12/seed-0/2021-06-09_17-06-26/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-vggish-vggsound/7e2eda12/seed-0/2021-06-09_17-06-26/summary-seed-0_seed-1_seed-2.json) |
| MoEE - VGGish + VGGSound   | t2v  | <sub><sup>22.5<sub>(0.3)</sub></sup></sub> | <sub><sup>54.4<sub>(0.6)</sub></sup></sub> | <sub><sup>69.5<sub>(0.9)</sub></sup></sub> | <sub><sup>92.4<sub>(0.4)</sub></sup></sub> | <sub><sup>5.0<sub>(0.0)</sub></sup></sub> | <sub><sup>17.8<sub>(1.1)</sub></sup></sub> | <sub><sup>44.0<sub>(0.4)</sub></sup></sub> | 8.9M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-vggish-vggsound-moee/f66525f8/seed-0/2021-06-09_16-44-00/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-vggish-vggsound-moee/f66525f8/seed-0/2021-06-09_16-44-00/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-vggish-vggsound-moee/f66525f8/seed-0/2021-06-09_16-44-00/summary-seed-0_seed-1_seed-2.json) |
| MoEE - VGGish + VGGSound   | v2t  | <sub><sup>25.1<sub>(0.8)</sub></sup></sub> | <sub><sup>57.5<sub>(1.4)</sub></sup></sub> | <sub><sup>72.9<sub>(1.2)</sub></sup></sub> | <sub><sup>93.2<sub>(0.8)</sub></sup></sub> | <sub><sup>4.0<sub>(0.0)</sub></sup></sub> | <sub><sup>15.6<sub>(0.5)</sub></sup></sub> | <sub><sup>47.2<sub>(1.0)</sub></sup></sub> | 8.9M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-vggish-vggsound-moee/f66525f8/seed-0/2021-06-09_16-44-00/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-vggish-vggsound-moee/f66525f8/seed-0/2021-06-09_16-44-00/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-vggish-vggsound-moee/f66525f8/seed-0/2021-06-09_16-44-00/summary-seed-0_seed-1_seed-2.json) |


#### Using only visual experts for AudioCaps:

| Experts | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Geom | params | Links |
| ----- | ---- | --- | --- | ---- | ---- | --- | --- | ----- | -- | -- |
| CE - Scene   | t2v  | <sub><sup>6.1<sub>(0.4)</sub></sup></sub> | <sub><sup>22.6<sub>(0.9)</sub></sup></sub> | <sub><sup>35.8<sub>(0.6)</sub></sup></sub> | <sub><sup>69.8<sub>(0.4)</sub></sup></sub> | <sub><sup>19.3<sub>(0.6)</sub></sup></sub> | <sub><sup>69.3<sub>(5.7)</sub></sup></sub> | <sub><sup>17.0<sub>(0.5)</sub></sup></sub> | 7.51M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-only-scene/74d71d8b/seed-0/2021-06-10_15-27-11/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-only-scene/74d71d8b/seed-0/2021-06-10_15-27-11/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-only-scene/74d71d8b/seed-0/2021-06-10_15-27-11/summary-seed-0_seed-1_seed-2.json) |
| CE - Scene    | v2t  | <sub><sup>6.5<sub>(0.8)</sub></sup></sub> | <sub><sup>21.8<sub>(1.2)</sub></sup></sub> | <sub><sup>31.3<sub>(1.6)</sub></sup></sub> | <sub><sup>63.5<sub>(2.1)</sub></sup></sub> | <sub><sup>26.1<sub>(2.6)</sub></sup></sub> | <sub><sup>121.1<sub>(3.1)</sub></sup></sub> | <sub><sup>16.4<sub>(1.0)</sub></sup></sub> | 7.51M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-only-scene/74d71d8b/seed-0/2021-06-10_15-27-11/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-only-scene/74d71d8b/seed-0/2021-06-10_15-27-11/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-only-scene/74d71d8b/seed-0/2021-06-10_15-27-11/summary-seed-0_seed-1_seed-2.json) |
| CE - R2P1D   | t2v  | <sub><sup>8.2<sub>(0.5)</sub></sup></sub> | <sub><sup>28.9<sub>(0.8)</sub></sup></sub> | <sub><sup>44.7<sub>(0.9)</sub></sup></sub> | <sub><sup>76.6<sub>(1.3)</sub></sup></sub> | <sub><sup>12.7<sub>(0.6)</sub></sup></sub> | <sub><sup>58.3<sub>(9.2)</sub></sup></sub> | <sub><sup>22.0<sub>(0.8)</sub></sup></sub> | 6.21M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-only-r2p1d/88d3ab9e/seed-0/2021-06-10_15-30-03/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-only-r2p1d/88d3ab9e/seed-0/2021-06-10_15-30-03/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-only-r2p1d/88d3ab9e/seed-0/2021-06-10_15-30-03/summary-seed-0_seed-1_seed-2.json) |
| CE - R2P1D   | v2t  | <sub><sup>10.3<sub>(0.4)</sub></sup></sub> | <sub><sup>28.7<sub>(1.5)</sub></sup></sub> | <sub><sup>41.8<sub>(3.1)</sub></sup></sub> | <sub><sup>75.6<sub>(1.3)</sub></sup></sub> | <sub><sup>15.4<sub>(1.5)</sub></sup></sub> | <sub><sup>82.0<sub>(7.9)</sub></sup></sub> | <sub><sup>23.1<sub>(0.9)</sub></sup></sub> | 6.21M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-only-r2p1d/88d3ab9e/seed-0/2021-06-10_15-30-03/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-only-r2p1d/88d3ab9e/seed-0/2021-06-10_15-30-03/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-only-r2p1d/88d3ab9e/seed-0/2021-06-10_15-30-03/summary-seed-0_seed-1_seed-2.json) |
| CE - Inst    | t2v  | <sub><sup>7.7<sub>(0.2)</sub></sup></sub> | <sub><sup>29.4<sub>(1.3)</sub></sup></sub> | <sub><sup>46.7<sub>(1.3)</sub></sup></sub> | <sub><sup>79.3<sub>(0.6)</sub></sup></sub> | <sub><sup>11.7<sub>(0.6)</sub></sup></sub> | <sub><sup>50.8<sub>(3.2)</sub></sup></sub> | <sub><sup>21.9<sub>(0.7)</sub></sup></sub> | 7.38M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-only-inst/5ee05383/seed-0/2021-06-10_15-32-29/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-only-inst/5ee05383/seed-0/2021-06-10_15-32-29/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-only-inst/5ee05383/seed-0/2021-06-10_15-32-29/summary-seed-0_seed-1_seed-2.json) |
| CE - Inst   | v2t  | <sub><sup>9.8<sub>(0.9)</sub></sup></sub> | <sub><sup>28.0<sub>(0.7)</sub></sup></sub> | <sub><sup>40.6<sub>(0.7)</sub></sup></sub> | <sub><sup>74.2<sub>(2.1)</sub></sup></sub> | <sub><sup>16.3<sub>(0.6)</sub></sup></sub> | <sub><sup>89.4<sub>(3.4)</sub></sup></sub> | <sub><sup>22.3<sub>(0.7)</sub></sup></sub> | 7.38M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-only-inst/5ee05383/seed-0/2021-06-10_15-32-29/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-only-inst/5ee05383/seed-0/2021-06-10_15-32-29/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-only-inst/5ee05383/seed-0/2021-06-10_15-32-29/summary-seed-0_seed-1_seed-2.json) |
| CE - Scene + R2P1D   | t2v  | <sub><sup>8.8<sub>(0.1)</sub></sup></sub> | <sub><sup>31.5<sub>(0.5)</sub></sup></sub> | <sub><sup>46.8<sub>(0.1)</sub></sup></sub> | <sub><sup>77.1<sub>(2.4)</sub></sup></sub> | <sub><sup>12.0<sub>(0.0)</sub></sup></sub> | <sub><sup>57.8<sub>(8.5)</sub></sup></sub> | <sub><sup>23.5<sub>(0.2)</sub></sup></sub> | 16.07M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-scene-r2p1d/b2b14107/seed-0/2021-06-10_15-13-04/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-scene-r2p1d/b2b14107/seed-0/2021-06-10_15-13-04/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-scene-r2p1d/b2b14107/seed-0/2021-06-10_15-13-04/summary-seed-0_seed-1_seed-2.json) |
| CE - Scene + R2P1D   | v2t  | <sub><sup>11.0<sub>(0.6)</sub></sup></sub> | <sub><sup>31.3<sub>(1.7)</sub></sup></sub> | <sub><sup>45.1<sub>(1.7)</sub></sup></sub> | <sub><sup>75.9<sub>(0.9)</sub></sup></sub> | <sub><sup>13.0<sub>(1.0)</sub></sup></sub> | <sub><sup>73.0<sub>(5.2)</sub></sup></sub> | <sub><sup>25.0<sub>(1.2)</sub></sup></sub> | 16.07M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-scene-r2p1d/b2b14107/seed-0/2021-06-10_15-13-04/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-scene-r2p1d/b2b14107/seed-0/2021-06-10_15-13-04/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-scene-r2p1d/b2b14107/seed-0/2021-06-10_15-13-04/summary-seed-0_seed-1_seed-2.json) |
| CE - Scene + Inst   | t2v  | <sub><sup>8.7<sub>(0.5)</sub></sup></sub> | <sub><sup>30.4<sub>(0.9)</sub></sup></sub> | <sub><sup>47.4<sub>(0.5)</sub></sup></sub> | <sub><sup>78.8<sub>(1.4)</sub></sup></sub> | <sub><sup>11.7<sub>(0.6)</sub></sup></sub> | <sub><sup>53.0<sub>(6.4)</sub></sup></sub> | <sub><sup>23.2<sub>(0.7)</sub></sup></sub> | 17.25M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-scene-inst/55c40cc6/seed-0/2021-06-10_15-18-50/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-scene-inst/55c40cc6/seed-0/2021-06-10_15-18-50/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-scene-inst/55c40cc6/seed-0/2021-06-10_15-18-50/summary-seed-0_seed-1_seed-2.json) |
| CE - Scene + Inst   | v2t  | <sub><sup>10.6<sub>(0.6)</sub></sup></sub> | <sub><sup>28.0<sub>(1.6)</sub></sup></sub> | <sub><sup>41.4<sub>(1.5)</sub></sup></sub> | <sub><sup>74.6<sub>(1.0)</sub></sup></sub> | <sub><sup>15.3<sub>(1.2)</sub></sup></sub> | <sub><sup>85.1<sub>(0.6)</sub></sup></sub> | <sub><sup>23.1<sub>(1.2)</sub></sup></sub> | 17.25M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-scene-inst/55c40cc6/seed-0/2021-06-10_15-18-50/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-scene-inst/55c40cc6/seed-0/2021-06-10_15-18-50/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-scene-inst/55c40cc6/seed-0/2021-06-10_15-18-50/summary-seed-0_seed-1_seed-2.json) |
| CE - R2P1D + Inst   | t2v  | <sub><sup>10.1<sub>(0.2)</sub></sup></sub> | <sub><sup>33.2<sub>(0.7)</sub></sup></sub> | <sub><sup>49.6<sub>(1.1)</sub></sup></sub> | <sub><sup>77.9<sub>(2.3)</sub></sup></sub> | <sub><sup>10.7<sub>(0.6)</sub></sup></sub> | <sub><sup>57.8<sub>(8.1)</sub></sup></sub> | <sub><sup>25.5<sub>(0.2)</sub></sup></sub> | 15.95M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-r2p1d-inst/cf11d710/seed-0/2021-06-10_15-23-04/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-r2p1d-inst/cf11d710/seed-0/2021-06-10_15-23-04/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-r2p1d-inst/cf11d710/seed-0/2021-06-10_15-23-04/summary-seed-0_seed-1_seed-2.json) |
| CE - R2P1D + Inst   | v2t  | <sub><sup>12.1<sub>(0.4)</sub></sup></sub> | <sub><sup>32.2<sub>(0.7)</sub></sup></sub> | <sub><sup>46.1<sub>(1.3)</sub></sup></sub> | <sub><sup>78.0<sub>(0.8)</sub></sup></sub> | <sub><sup>12.8<sub>(0.7)</sub></sup></sub> | <sub><sup>71.8<sub>(4.5)</sub></sup></sub> | <sub><sup>26.2<sub>(0.5)</sub></sup></sub> | 15.95M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-r2p1d-inst/cf11d710/seed-0/2021-06-10_15-23-04/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-r2p1d-inst/cf11d710/seed-0/2021-06-10_15-23-04/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-r2p1d-inst/cf11d710/seed-0/2021-06-10_15-23-04/summary-seed-0_seed-1_seed-2.json) |


#### Visual and audio experts for AudioCaps:

| Experts | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Geom | params | Links |
| ----- | ---- | --- | --- | ---- | ---- | --- | --- | ----- | -- | -- |
| CE - R2P1D + Inst + VGGish   | t2v  | <sub><sup>23.9<sub>(0.7)</sub></sup></sub> | <sub><sup>58.8<sub>(0.2)</sub></sup></sub> | <sub><sup>74.4<sub>(0.2)</sub></sup></sub> | <sub><sup>94.5<sub>(0.2)</sub></sup></sub> | <sub><sup>4.0<sub>(0.0)</sub></sup></sub> | <sub><sup>14.0<sub>(0.7)</sub></sup></sub> | <sub><sup>47.1<sub>(0.5)</sub></sup></sub> | 23.32M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-r2p1d-inst-vggish/74991f95/seed-0/2021-06-10_15-06-31/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-r2p1d-inst-vggish/74991f95/seed-0/2021-06-10_15-06-31/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-r2p1d-inst-vggish/74991f95/seed-0/2021-06-10_15-06-31/summary-seed-0_seed-1_seed-2.json) |
| CE - R2P1D + Inst + VGGish  | v2t  | <sub><sup>29.0<sub>(2.0)</sub></sup></sub> | <sub><sup>63.5<sub>(2.5)</sub></sup></sub> | <sub><sup>77.2<sub>(1.9)</sub></sup></sub> | <sub><sup>95.0<sub>(0.1)</sub></sup></sub> | <sub><sup>3.0<sub>(0.0)</sub></sup></sub> | <sub><sup>12.7<sub>(0.1)</sub></sup></sub> | <sub><sup>52.2<sub>(2.2)</sub></sup></sub> | 23.32M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-r2p1d-inst-vggish/74991f95/seed-0/2021-06-10_15-06-31/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-r2p1d-inst-vggish/74991f95/seed-0/2021-06-10_15-06-31/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-r2p1d-inst-vggish/74991f95/seed-0/2021-06-10_15-06-31/summary-seed-0_seed-1_seed-2.json) |
| CE - R2P1D + Inst + VGGSound   | t2v  | <sub><sup>27.4<sub>(0.7)</sub></sup></sub> | <sub><sup>62.8<sub>(0.7)</sub></sup></sub> | <sub><sup>78.2<sub>(0.3)</sub></sup></sub> | <sub><sup>94.9<sub>(0.3)</sub></sup></sub> | <sub><sup>3.0<sub>(0.0)</sub></sup></sub> | <sub><sup>13.1<sub>(0.6)</sub></sup></sub> | <sub><sup>51.3<sub>(0.5)</sub></sup></sub> | 28.05M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-r2p1d-inst-vggsound/1b623fdc/seed-0/2021-06-10_14-49-00/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-r2p1d-inst-vggsound/1b623fdc/seed-0/2021-06-10_14-49-00/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-r2p1d-inst-vggsound/1b623fdc/seed-0/2021-06-10_14-49-00/summary-seed-0_seed-1_seed-2.json) |
| CE - R2P1D + Inst + VGGSound  | v2t  | <sub><sup>34.0<sub>(1.5)</sub></sup></sub> | <sub><sup>68.5<sub>(1.3)</sub></sup></sub> | <sub><sup>82.5<sub>(1.2)</sub></sup></sub> | <sub><sup>97.3<sub>(0.4)</sub></sup></sub> | <sub><sup>2.7<sub>(0.6)</sub></sup></sub> | <sub><sup>9.1<sub>(0.3)</sub></sup></sub> | <sub><sup>57.7<sub>(1.3)</sub></sup></sub> | 28.05M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-r2p1d-inst-vggsound/1b623fdc/seed-0/2021-06-10_14-49-00/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-r2p1d-inst-vggsound/1b623fdc/seed-0/2021-06-10_14-49-00/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-r2p1d-inst-vggsound/1b623fdc/seed-0/2021-06-10_14-49-00/summary-seed-0_seed-1_seed-2.json) |
| CE - R2P1D + Inst +VGGish + VGGSound  | t2v  | <sub><sup>28.1<sub>(0.6)</sub></sup></sub> | <sub><sup>64.0<sub>(0.5)</sub></sup></sub> | <sub><sup>79.0<sub>(0.5)</sub></sup></sub> | <sub><sup>95.4<sub>(0.6)</sub></sup></sub> | <sub><sup>3.0<sub>(0.0)</sub></sup></sub> | <sub><sup>12.1<sub>(1.1)</sub></sup></sub> | <sub><sup>52.2<sub>(0.4)</sub></sup></sub> | 35.43M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-r2p1d-inst-vggish-vggsound/b51f941a/seed-0/2021-06-10_14-56-45/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-r2p1d-inst-vggish-vggsound/b51f941a/seed-0/2021-06-10_14-56-45/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-r2p1d-inst-vggish-vggsound/b51f941a/seed-0/2021-06-10_14-56-45/summary-seed-0_seed-1_seed-2.json) |
| CE - R2P1D + Inst +VGGish + VGGSound  | v2t  | <sub><sup>33.7<sub>(1.6)</sub></sup></sub> | <sub><sup>70.2<sub>(0.8)</sub></sup></sub> | <sub><sup>83.7<sub>(0.4)</sub></sup></sub> | <sub><sup>97.5<sub>(0.1)</sub></sup></sub> | <sub><sup>2.7<sub>(0.3)</sub></sup></sub> | <sub><sup>8.1<sub>(0.4)</sub></sup></sub> | <sub><sup>58.3<sub>(1.2)</sub></sup></sub> | 35.43M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-r2p1d-inst-vggish-vggsound/b51f941a/seed-0/2021-06-10_14-56-45/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/audiocaps-train-full-ce-r2p1d-inst-vggish-vggsound/b51f941a/seed-0/2021-06-10_14-56-45/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/audiocaps-train-full-ce-r2p1d-inst-vggish-vggsound/b51f941a/seed-0/2021-06-10_14-56-45/summary-seed-0_seed-1_seed-2.json) |

### CLOTHO

| Experts | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Geom | params | Links |
| ----- | ---- | --- | --- | ---- | ---- | --- | --- | ----- | -- | -- |
| CE - VGGish   | t2v  | <sub><sup>4.0<sub>(0.2)</sub></sup></sub> | <sub><sup>15.0<sub>(0.9)</sub></sup></sub> | <sub><sup>25.4<sub>(0.5)</sub></sup></sub> | <sub><sup>61.4<sub>(1.1)</sub></sup></sub> | <sub><sup>31.7<sub>(1.5)</sub></sup></sub> | <sub><sup>78.2<sub>(2.2)</sub></sup></sub> | <sub><sup>11.5<sub>(0.5)</sub></sup></sub> | 7.39M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-full-ce-only-audio/4f58ef05/seed-0/2021-06-10_15-38-28/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-full-ce-only-audio/4f58ef05/seed-0/2021-06-10_15-38-28/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/clotho-train-full-ce-only-audio/4f58ef05/seed-0/2021-06-10_15-38-28/summary-seed-0_seed-1_seed-2.json) |
| CE - VGGish   | v2t  | <sub><sup>4.8<sub>(0.4)</sub></sup></sub> | <sub><sup>15.9<sub>(1.8)</sub></sup></sub> | <sub><sup>25.8<sub>(1.7)</sub></sup></sub> | <sub><sup>57.5<sub>(2.5)</sub></sup></sub> | <sub><sup>35.7<sub>(2.5)</sub></sup></sub> | <sub><sup>106.6<sub>(5.7)</sub></sup></sub> | <sub><sup>12.5<sub>(1.0)</sub></sup></sub> | 7.39M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-full-ce-only-audio/4f58ef05/seed-0/2021-06-10_15-38-28/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-full-ce-only-audio/4f58ef05/seed-0/2021-06-10_15-38-28/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/clotho-train-full-ce-only-audio/4f58ef05/seed-0/2021-06-10_15-38-28/summary-seed-0_seed-1_seed-2.json) |
| CE - VGGish + VGGSound    | t2v  | <sub><sup>6.7<sub>(0.4)</sub></sup></sub> | <sub><sup>21.6<sub>(0.6)</sub></sup></sub> | <sub><sup>33.2<sub>(0.3)</sub></sup></sub> | <sub><sup>69.8<sub>(0.3)</sub></sup></sub> | <sub><sup>22.3<sub>(0.6)</sub></sup></sub> | <sub><sup>58.3<sub>(1.1)</sub></sup></sub> | <sub><sup>16.9<sub>(0.2)</sub></sup></sub> | 21.86M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-vggish-vggsound/dec0c820/seed-0/2021-06-10_14-45-51/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-vggish-vggsound/dec0c820/seed-0/2021-06-10_14-45-51/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/clotho-train-vggish-vggsound/dec0c820/seed-0/2021-06-10_14-45-51/summary-seed-0_seed-1_seed-2.json) |
| CE - VGGish + VGGSound   | v2t  | <sub><sup>7.1<sub>(0.3)</sub></sup></sub> | <sub><sup>22.7<sub>(0.6)</sub></sup></sub> | <sub><sup>34.6<sub>(0.5)</sub></sup></sub> | <sub><sup>67.9<sub>(2.3)</sub></sup></sub> | <sub><sup>21.3<sub>(0.6)</sub></sup></sub> | <sub><sup>72.6<sub>(3.4)</sub></sup></sub> | <sub><sup>17.7<sub>(0.4)</sub></sup></sub> | 21.86M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-vggish-vggsound/dec0c820/seed-0/2021-06-10_14-45-51/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-vggish-vggsound/dec0c820/seed-0/2021-06-10_14-45-51/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/clotho-train-vggish-vggsound/dec0c820/seed-0/2021-06-10_14-45-51/summary-seed-0_seed-1_seed-2.json) |
| MoEE - VGGish + VGGSound   | t2v  | <sub><sup>6.0<sub>(0.1)</sub></sup></sub> | <sub><sup>20.8<sub>(0.7)</sub></sup></sub> | <sub><sup>32.3<sub>(0.3)</sub></sup></sub> | <sub><sup>68.5<sub>(0.5)</sub></sup></sub> | <sub><sup>23.0<sub>(0.0)</sub></sup></sub> | <sub><sup>60.2<sub>(0.8)</sub></sup></sub> | <sub><sup>16.0<sub>(0.3)</sub></sup></sub> | 8.9M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-vggish-vggsound-moee/fafa3e91/seed-0/2021-06-10_14-44-51/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-vggish-vggsound-moee/fafa3e91/seed-0/2021-06-10_14-44-51/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/clotho-train-vggish-vggsound-moee/fafa3e91/seed-0/2021-06-10_14-44-51/summary-seed-0_seed-1_seed-2.json) |
| MoEE - VGGish + VGGSound   | v2t  | <sub><sup>7.2<sub>(0.5)</sub></sup></sub> | <sub><sup>22.1<sub>(0.7)</sub></sup></sub> | <sub><sup>33.2<sub>(1.1)</sub></sup></sub> | <sub><sup>67.4<sub>(0.3)</sub></sup></sub> | <sub><sup>22.7<sub>(0.6)</sub></sup></sub> | <sub><sup>71.8<sub>(2.3)</sub></sup></sub> | <sub><sup>17.4<sub>(0.7)</sub></sup></sub> | 8.9M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-vggish-vggsound-moee/fafa3e91/seed-0/2021-06-10_14-44-51/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-vggish-vggsound-moee/fafa3e91/seed-0/2021-06-10_14-44-51/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/clotho-train-vggish-vggsound-moee/fafa3e91/seed-0/2021-06-10_14-44-51/summary-seed-0_seed-1_seed-2.json) |

### Pretraining on AudioCaps, finetuning on CLOTHO
| Experts | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Geom | params | Links |
| ----- | ---- | --- | --- | ---- | ---- | --- | --- | ----- | -- | -- |
| CE - VGGish + VGGSound   | t2v  | <sub><sup>9.6<sub>(0.3)</sub></sup></sub> | <sub><sup>27.7<sub>(0.5)</sub></sup></sub> | <sub><sup>40.1<sub>(0.7)</sub></sup></sub> | <sub><sup>75.0<sub>(0.8)</sub></sup></sub> | <sub><sup>17.0<sub>(1.0)</sub></sup></sub> | <sub><sup>48.4<sub>(0.7)</sub></sup></sub> | <sub><sup>22.0<sub>(0.3)</sub></sup></sub> | 21.86M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-vggish-vggsound-finetuned/74560a6c/seed-0/2021-06-10_16-38-40/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-vggish-vggsound-finetuned/74560a6c/seed-0/2021-06-10_16-38-40/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/clotho-train-vggish-vggsound-finetuned/74560a6c/seed-0/2021-06-10_16-38-40/summary-seed-0_seed-1_seed-2.json) |
| CE - VGGish + VGGSound    | v2t  | <sub><sup>10.7<sub>(0.6)</sub></sup></sub> | <sub><sup>29.0<sub>(1.9)</sub></sup></sub> | <sub><sup>40.8<sub>(1.4)</sub></sup></sub> | <sub><sup>73.5<sub>(2.5)</sub></sup></sub> | <sub><sup>16.0<sub>(1.7)</sub></sup></sub> | <sub><sup>58.9<sub>(3.8)</sub></sup></sub> | <sub><sup>23.3<sub>(1.1)</sub></sup></sub> | 21.86M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-vggish-vggsound-finetuned/74560a6c/seed-0/2021-06-10_16-38-40/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-vggish-vggsound-finetuned/74560a6c/seed-0/2021-06-10_16-38-40/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/clotho-train-vggish-vggsound-finetuned/74560a6c/seed-0/2021-06-10_16-38-40/summary-seed-0_seed-1_seed-2.json) |
| MoEE - VGGish + VGGSound   | t2v  | <sub><sup>8.6<sub>(0.4)</sub></sup></sub> | <sub><sup>27.0<sub>(0.5)</sub></sup></sub> | <sub><sup>39.3<sub>(0.7)</sub></sup></sub> | <sub><sup>74.4<sub>(0.5)</sub></sup></sub> | <sub><sup>17.3<sub>(0.6)</sub></sup></sub> | <sub><sup>49.0<sub>(1.0)</sub></sup></sub> | <sub><sup>20.9<sub>(0.5)</sub></sup></sub> | 8.9M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-vggish-vggsound-moee-finetuned/5395fa47/seed-0/2021-06-10_16-36-13/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-vggish-vggsound-moee-finetuned/5395fa47/seed-0/2021-06-10_16-36-13/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/clotho-train-vggish-vggsound-moee-finetuned/5395fa47/seed-0/2021-06-10_16-36-13/summary-seed-0_seed-1_seed-2.json) |
| MoEE - VGGish + VGGSound    | v2t  | <sub><sup>10.0<sub>(0.3)</sub></sup></sub> | <sub><sup>27.7<sub>(0.9)</sub></sup></sub> | <sub><sup>40.1<sub>(1.3)</sub></sup></sub> | <sub><sup>73.5<sub>(1.0)</sub></sup></sub> | <sub><sup>16.0<sub>(1.0)</sub></sup></sub> | <sub><sup>55.9<sub>(1.8)</sub></sup></sub> | <sub><sup>22.3<sub>(0.0)</sub></sup></sub> | 8.9M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-vggish-vggsound-moee-finetuned/5395fa47/seed-0/2021-06-10_16-36-13/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/clotho-train-vggish-vggsound-moee-finetuned/5395fa47/seed-0/2021-06-10_16-36-13/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/clotho-train-vggish-vggsound-moee-finetuned/5395fa47/seed-0/2021-06-10_16-36-13/summary-seed-0_seed-1_seed-2.json) |




### Visual centric datasets
| Experts | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Geom | params | Links |
| ----- | ---- | --- | --- | ---- | ---- | --- | --- | ----- | -- | -- |
| CE - VGGish QuerYD  | t2v  | <sub><sup>3.7<sub>(0.2)</sub></sup></sub> | <sub><sup>11.7<sub>(0.4)</sub></sup></sub> | <sub><sup>17.3<sub>(0.6)</sub></sup></sub> | <sub><sup>36.3<sub>(0.3)</sub></sup></sub> | <sub><sup>115.5<sub>(5.2)</sub></sup></sub> | <sub><sup>273.5<sub>(6.7)</sub></sup></sub> | <sub><sup>9.0<sub>(0.0)</sub></sup></sub> | 7.39M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/querydsegments-train-full-ce-only-audio/70111434/seed-0/2021-06-10_14-33-03/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/querydsegments-train-full-ce-only-audio/70111434/seed-0/2021-06-10_14-33-03/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/querydsegments-train-full-ce-only-audio/70111434/seed-0/2021-06-10_14-33-03/summary-seed-0_seed-1_seed-2.json) |
| CE - VGGish QuerYD   | v2t  | <sub><sup>3.8<sub>(0.2)</sub></sup></sub> | <sub><sup>11.5<sub>(0.4)</sub></sup></sub> | <sub><sup>16.8<sub>(0.2)</sub></sup></sub> | <sub><sup>35.2<sub>(0.4)</sub></sup></sub> | <sub><sup>116.3<sub>(2.1)</sub></sup></sub> | <sub><sup>271.9<sub>(5.8)</sub></sup></sub> | <sub><sup>9.0<sub>(0.3)</sub></sup></sub> | 7.39M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/querydsegments-train-full-ce-only-audio/70111434/seed-0/2021-06-10_14-33-03/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/querydsegments-train-full-ce-only-audio/70111434/seed-0/2021-06-10_14-33-03/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/querydsegments-train-full-ce-only-audio/70111434/seed-0/2021-06-10_14-33-03/summary-seed-0_seed-1_seed-2.json) |
| CE - VGGish Activity-Net  | t2v  | <sub><sup>1.5<sub>(0.1)</sub></sup></sub> | <sub><sup>5.6<sub>(0.2)</sub></sup></sub> | <sub><sup>9.2<sub>(0.3)</sub></sup></sub> | <sub><sup>22.1<sub>(1.2)</sub></sup></sub> | <sub><sup>373.0<sub>(46.5)</sub></sup></sub> | <sub><sup>907.8<sub>(56.2)</sub></sup></sub> | <sub><sup>4.0<sub>(0.1)</sub></sup></sub> | 7.39M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/activity-net-train-full-ce-audio-only/f3ebaada/seed-0/2021-07-22_12-44-19/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/activity-net-train-full-ce-audio-only/f3ebaada/seed-0/2021-07-22_12-44-19/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/activity-net-train-full-ce-audio-only/f3ebaada/seed-0/2021-07-22_12-44-19/summary-seed-0_seed-1_seed-2.json) |
| CE - VGGish Activity-Net   | v2t  | <sub><sup>1.4<sub>(0.1)</sub></sup></sub> | <sub><sup>5.3<sub>(0.1)</sub></sup></sub> | <sub><sup>8.5<sub>(0.3)</sub></sup></sub> | <sub><sup>21.9<sub>(1.3)</sub></sup></sub> | <sub><sup>370.0<sub>(40.5)</sub></sup></sub> | <sub><sup>912.1<sub>(51.6)</sub></sup></sub> | <sub><sup>4.3<sub>(0.1)</sub></sup></sub> | 7.39M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/activity-net-train-full-ce-audio-only/f3ebaada/seed-0/2021-07-22_12-44-19/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/activity-net-train-full-ce-audio-only/f3ebaada/seed-0/2021-07-22_12-44-19/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/activity-net-train-full-ce-audio-only/f3ebaada/seed-0/2021-07-22_12-44-19/summary-seed-0_seed-1_seed-2.json) |


#### More information can be found at our project page: https://www.robots.ox.ac.uk/~vgg/research/audio-retrieval/

#### This code is based on https://github.com/albanie/collaborative-experts

### References
[1] If you find this code useful, please consider citing:
```
@inproceedings{Oncescu21a,
               author       = "Oncescu, A.-M. and Koepke, A.S. and Henriques, J. and Akata, Z., Albanie, S.",
               title        = "Audio Retrieval with Natural Language Queries",
               booktitle    = "INTERSPEECH",
               year         = "2021"
             }
``` 

[2] If you find this code useful, please consider citing:
```
@inproceedings{Liu2019a,
  author    = {Liu, Y. and Albanie, S. and Nagrani, A. and Zisserman, A.},
  booktitle = {arXiv preprint arxiv:1907.13487},
  title     = {Use What You Have: Video retrieval using representations from collaborative experts},
  date      = {2019},
}
```
